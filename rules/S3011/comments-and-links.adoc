=== On 2015-07-23T07:15:31Z Nicolas Peru Wrote:
Not sure if it should be part of the description but it is not really clear if the rule is limited to the API in the example.

=== On 2015-07-23T09:05:19Z Ann Campbell Wrote:
FYI [~tamas.vajk]

=== On 2018-04-19T10:53:30Z Alexandre Gigleux Wrote:
This is a "Security Weakness".

=== On 2018-09-04T10:28:09Z Alexandre Gigleux Wrote:
\[~nicolas.harraudeau] Review 

I think you should ask yourself if this rule is only relevant for Java. If this is the case, it is no longer a Common Security Hotspot rule.

Check if C#, VB.Net are really excluded, I don't think so. Also I believe PHP, Swift, Scala, Kotlin, Ruby should be in the list of Targeted Languages. 



=== On 2018-09-04T11:29:31Z Nicolas Harraudeau Wrote:
\[~alexandre.gigleux] Thanks for the review

Here are examples for the targeted languages: \https://rosettacode.org/wiki/Break_OO_privacy

Ruby is a special case.

=== On 2020-04-06T12:01:04Z Eric Therond Wrote:
Altering accessibility at run-time is not possible if a security manager is configured (in Java) or the code doesn't have the right permission (https://docs.microsoft.com/fr-fr/dotnet/framework/reflection-and-codedom/security-considerations-for-reflection[in C#]).


So a new security-hotspot rule could be relevant in the future to detect when a loose permission is granted that allow, for instance, external code to change accessibility of fields of a trusted code and thus access to private information, however here:

* The rule raises when the accessibility is changed, so basically "the consequence" and not the root cause of the bug is highlighted.
* Reflection will be most of the times used to create dynamic types or to perform debugging.

So a code smell is more appropriate than a security rule.



